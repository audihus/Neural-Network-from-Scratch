{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cd2d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a014ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49d14af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f528a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1de483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audih\\AppData\\Local\\Temp\\ipykernel_15356\\201093094.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[nominal_cols] = df[nominal_cols].replace({\"yes\": 1, \"no\": 0})\n"
     ]
    }
   ],
   "source": [
    "nominal_cols = ['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']\n",
    "\n",
    "df[nominal_cols] = df[nominal_cols].replace({\"yes\": 1, \"no\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2daea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['furnished', 'semi-furnished', 'unfurnished'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['furnishingstatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8329d1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
       "0  13300000  7420         4          2        3         1          0   \n",
       "1  12250000  8960         4          4        4         1          0   \n",
       "2  12250000  9960         3          2        2         1          0   \n",
       "3  12215000  7500         4          2        2         1          0   \n",
       "4  11410000  7420         4          1        2         1          1   \n",
       "\n",
       "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
       "0         0                0                1        2         1   \n",
       "1         0                0                1        3         0   \n",
       "2         1                0                0        2         1   \n",
       "3         1                0                1        3         1   \n",
       "4         1                0                1        2         0   \n",
       "\n",
       "   furnishingstatus  \n",
       "0                 2  \n",
       "1                 2  \n",
       "2                 1  \n",
       "3                 2  \n",
       "4                 2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df['furnishingstatus'] = le.fit_transform(df['furnishingstatus'])\n",
    "\n",
    "furnishingstatus_order = {'furnished' : 2, 'semi-furnished': 1, 'unfurnished': 0}\n",
    "df['furnishingstatus'] = df['furnishingstatus'].map(furnishingstatus_order)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2562b997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>545.0</td>\n",
       "      <td>4.766729e+06</td>\n",
       "      <td>1.870440e+06</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>3430000.0</td>\n",
       "      <td>4340000.0</td>\n",
       "      <td>5740000.0</td>\n",
       "      <td>13300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>545.0</td>\n",
       "      <td>5.150541e+03</td>\n",
       "      <td>2.170141e+03</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>16200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>545.0</td>\n",
       "      <td>2.965138e+00</td>\n",
       "      <td>7.380639e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>545.0</td>\n",
       "      <td>1.286239e+00</td>\n",
       "      <td>5.024696e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stories</th>\n",
       "      <td>545.0</td>\n",
       "      <td>1.805505e+00</td>\n",
       "      <td>8.674925e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mainroad</th>\n",
       "      <td>545.0</td>\n",
       "      <td>8.587156e-01</td>\n",
       "      <td>3.486347e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guestroom</th>\n",
       "      <td>545.0</td>\n",
       "      <td>1.779817e-01</td>\n",
       "      <td>3.828487e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basement</th>\n",
       "      <td>545.0</td>\n",
       "      <td>3.504587e-01</td>\n",
       "      <td>4.775519e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hotwaterheating</th>\n",
       "      <td>545.0</td>\n",
       "      <td>4.587156e-02</td>\n",
       "      <td>2.093987e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airconditioning</th>\n",
       "      <td>545.0</td>\n",
       "      <td>3.155963e-01</td>\n",
       "      <td>4.651799e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking</th>\n",
       "      <td>545.0</td>\n",
       "      <td>6.935780e-01</td>\n",
       "      <td>8.615858e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefarea</th>\n",
       "      <td>545.0</td>\n",
       "      <td>2.348624e-01</td>\n",
       "      <td>4.243022e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furnishingstatus</th>\n",
       "      <td>545.0</td>\n",
       "      <td>9.302752e-01</td>\n",
       "      <td>7.613727e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std        min        25%  \\\n",
       "price             545.0  4.766729e+06  1.870440e+06  1750000.0  3430000.0   \n",
       "area              545.0  5.150541e+03  2.170141e+03     1650.0     3600.0   \n",
       "bedrooms          545.0  2.965138e+00  7.380639e-01        1.0        2.0   \n",
       "bathrooms         545.0  1.286239e+00  5.024696e-01        1.0        1.0   \n",
       "stories           545.0  1.805505e+00  8.674925e-01        1.0        1.0   \n",
       "mainroad          545.0  8.587156e-01  3.486347e-01        0.0        1.0   \n",
       "guestroom         545.0  1.779817e-01  3.828487e-01        0.0        0.0   \n",
       "basement          545.0  3.504587e-01  4.775519e-01        0.0        0.0   \n",
       "hotwaterheating   545.0  4.587156e-02  2.093987e-01        0.0        0.0   \n",
       "airconditioning   545.0  3.155963e-01  4.651799e-01        0.0        0.0   \n",
       "parking           545.0  6.935780e-01  8.615858e-01        0.0        0.0   \n",
       "prefarea          545.0  2.348624e-01  4.243022e-01        0.0        0.0   \n",
       "furnishingstatus  545.0  9.302752e-01  7.613727e-01        0.0        0.0   \n",
       "\n",
       "                        50%        75%         max  \n",
       "price             4340000.0  5740000.0  13300000.0  \n",
       "area                 4600.0     6360.0     16200.0  \n",
       "bedrooms                3.0        3.0         6.0  \n",
       "bathrooms               1.0        2.0         4.0  \n",
       "stories                 2.0        2.0         4.0  \n",
       "mainroad                1.0        1.0         1.0  \n",
       "guestroom               0.0        0.0         1.0  \n",
       "basement                0.0        1.0         1.0  \n",
       "hotwaterheating         0.0        0.0         1.0  \n",
       "airconditioning         0.0        1.0         1.0  \n",
       "parking                 0.0        1.0         3.0  \n",
       "prefarea                0.0        0.0         1.0  \n",
       "furnishingstatus        1.0        2.0         2.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "080c7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price'])\n",
    "y = df[[\"price\"]].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fe89cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fdda9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6129ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_cols = ['price','area']\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train[ ['area'] ] = scaler_X.fit_transform(X_train[['area']])\n",
    "X_val  [['area'] ] = scaler_X.transform(X_val[['area']])\n",
    "X_test [['area'] ] = scaler_X.transform(X_test[['area']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0936ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_val   = scaler_y.transform(y_val)\n",
    "y_test  = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca3977ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train).T\n",
    "Y_train_array = np.array(y_train).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92a0db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_array = np.array(X_val).T\n",
    "Y_val_array = np.array(y_val).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ba0c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEURAL NETWORKS\n",
    "\n",
    "def init_params(input_dim, hidden_neuron=32, method = \"xavier\", rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    if method == \"he\":\n",
    "        W1 = rng.standard_normal((hidden_neuron, input_dim)) * np.sqrt(2.0 / input_dim)\n",
    "        W2 = rng.standard_normal((1, hidden_neuron)) * np.sqrt(2.0 / hidden_neuron)\n",
    "    \n",
    "    elif method == \"xavier\":\n",
    "        W1 = np.random.randn(hidden_neuron, input_dim) * np.sqrt(1.0 / input_dim)\n",
    "        W2 = np.random.randn(1, hidden_neuron) * np.sqrt(1.0 / hidden_neuron)\n",
    "\n",
    "    # b1 = np.random.rand(hidden_neuron,1) #inisialisasi bias untuk layer 1\n",
    "    # b2 = np.random.rand(1,1) #inisialisasi bias untuk layer 2\n",
    "    b1 = np.zeros((hidden_neuron, 1))\n",
    "    b2 = np.zeros((1, 1))\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "\n",
    "def leaky_relu(Z,alpha=0.1):\n",
    "    return np.maximum(alpha*Z, Z)\n",
    "\n",
    "def deriv_leaky_relu(Z, alpha=0.1):\n",
    "    grad = np.ones_like(Z)\n",
    "    grad[Z < 0] = alpha\n",
    "    return grad\n",
    "\n",
    "def linear(Z):\n",
    "    return Z\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def deriv_relu(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def tanh(Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "def deriv_tanh(Z):\n",
    "    A = np.tanh(Z)\n",
    "    return 1 - np.power(A,2)\n",
    "\n",
    "\n",
    "def forward(W1, b1, W2, b2, X, activation = relu):\n",
    "    if activation == \"tanh\":\n",
    "            '''\n",
    "            Layer 1\n",
    "            '''\n",
    "            #Z1 adalah sum dari layer 1\n",
    "            Z1 = W1.dot(X) + b1\n",
    "            #A1 adalah output dari layer 1\n",
    "            A1 = tanh(Z1)\n",
    "\n",
    "            '''\n",
    "            Layer 2\n",
    "            '''\n",
    "            Z2 = W2.dot(A1) + b2\n",
    "            A2 = linear(Z2)\n",
    "\n",
    "            return Z1, A1, Z2, A2\n",
    "    elif activation == \"leaky_relu\":\n",
    "            '''\n",
    "            Layer 1\n",
    "            '''\n",
    "            #Z1 adalah sum dari layer 1\n",
    "            Z1 = W1.dot(X) + b1\n",
    "            #A1 adalah output dari layer 1\n",
    "            A1 = leaky_relu(Z1,alpha=0.1)\n",
    "\n",
    "            '''\n",
    "            Layer 2\n",
    "            '''\n",
    "            Z2 = W2.dot(A1) + b2\n",
    "            A2 = linear(Z2)\n",
    "\n",
    "            return Z1, A1, Z2, A2\n",
    "    \n",
    "    '''\n",
    "    Layer 1\n",
    "    '''\n",
    "    #Z1 adalah sum dari layer 1\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    #A1 adalah output dari layer 1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    '''\n",
    "    Layer 2\n",
    "    '''\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = linear(Z2)\n",
    "\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backpropagation(Z1, A1, Z2, A2, W2, X, Y, activation = relu):\n",
    "    if activation == \"leaky_relu\":\n",
    "        m = Y.size\n",
    "        dZ2 = A2 - Y\n",
    "        dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "        dZ1 = W2.T.dot(dZ2) * deriv_leaky_relu(Z1,alpha=0.1)\n",
    "        dW1 = (1/m) * dZ1.dot(X.T)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        m = Y.size\n",
    "        dZ2 = A2 - Y\n",
    "        dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "        dZ1 = W2.T.dot(dZ2) * deriv_tanh(Z1)\n",
    "        dW1 = (1/m) * dZ1.dot(X.T)\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "        return dW1, db1, dW2, db2\n",
    "         \n",
    "    m = Y.size\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_relu(Z1)\n",
    "    dW1 = (1/m) * dZ1.dot(X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True) #kenapa gini\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    new_W1 = W1 - alpha * dW1\n",
    "    new_b1 = b1 - alpha * db1\n",
    "    new_W2 = W2 - alpha * dW2\n",
    "    new_b2 = b2 - alpha * db2\n",
    "    \n",
    "    return new_W1, new_b1, new_W2, new_b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "264f83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT DESCENT\n",
    "# fungsi untuk mengubah output aktivasi menjadi prediksi akhir\n",
    "def get_prediction(A2):\n",
    "    \"\"\"\n",
    "    Karena ini regresi, prediksi = output langsung\n",
    "    \"\"\"\n",
    "    return A2\n",
    "\n",
    "# fungsi untuk menghitung error (contoh MSE)\n",
    "def get_error(prediction, Y, loss=\"mse\"):\n",
    "    \"\"\"\n",
    "    Menghitung loss antara prediksi dan target.\n",
    "    prediction, Y: shape (1, m)\n",
    "    \"\"\"\n",
    "\n",
    "    pred_real = scaler_y.inverse_transform(prediction.T)\n",
    "    y_real    = scaler_y.inverse_transform(Y.T)\n",
    "\n",
    "    if loss == \"mse\":\n",
    "        return np.mean((pred_real - y_real) ** 2)\n",
    "    elif loss == \"mae\":\n",
    "        return np.mean(np.abs(pred_real - y_real))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss type\")\n",
    "\n",
    "\n",
    "\n",
    "def batch_gradient_descent(X,Y, epochs, lr,hidden_neuron, activation, winit):\n",
    "    input_dim = X.shape[0]\n",
    "    W1, b1, W2, b2 = init_params(input_dim, hidden_neuron, method=winit)\n",
    "    for i in range(1, epochs+1):\n",
    "        Z1, A1, Z2, A2 = forward(W1,b1,W2,b2,X, activation=activation)\n",
    "        dW1, db1, dW2, db2 = backpropagation(Z1,A1,Z2,A2,W2,X,Y, activation=activation)\n",
    "        W1, b1, W2, b2 = update_parameters(W1,b1,W2,b2,dW1,db1,dW2,db2,lr)\n",
    "\n",
    "        if i % 10 ==0:\n",
    "            pred = get_prediction(A2)\n",
    "            train_mae = get_error(pred, Y, loss=\"mae\")\n",
    "            # setelah update tiap epoch\n",
    "            _, _, _, A2_val = forward(W1, b1, W2, b2, X_val_array, activation=activation)\n",
    "            pred_val = get_prediction(A2_val)\n",
    "            val_mae = get_error(pred_val, Y_val_array, loss=\"mae\")\n",
    "            print(f\"Iter {i:4d} | Train error = {train_mae:.4f} | val error = {val_mae:.4f}\")\n",
    "    \n",
    "    experiments = []\n",
    "    experiments.append({\n",
    "        \"mode\" : \"Batch_Gradient_Descent\",\n",
    "        \"weight initialization\" : winit,\n",
    "        \"activation\" : activation,\n",
    "        \"learning_rate\" : lr,\n",
    "        \"train_mae\" : float(train_mae), \n",
    "        \"val_mae\" : float(val_mae), \n",
    "    })\n",
    "\n",
    "    results_df = pd.DataFrame(experiments)\n",
    "\n",
    "    # save results\n",
    "    results_csv = \"results3.csv\"\n",
    "    if not os.path.isfile(results_csv):\n",
    "        results_df.to_csv(results_csv, index=False, mode='w', header=True)\n",
    "    else:\n",
    "        results_df.to_csv(results_csv, index=False, mode='a', header=False)\n",
    "    print(\"\\nAll experiments done. Results:\")\n",
    "\n",
    "    print(f\"\\nSaved results to {results_csv}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "def stoch_gradient_descent(X, Y, epochs, lr, hidden_neuron, activation, winit, shuffle=True, seed=42):\n",
    "    input_dim = X.shape[0]\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    n = X.shape[1]  # jumlah record\n",
    "    W1, b1, W2, b2 = init_params(input_dim, hidden_neuron, method=winit)\n",
    "\n",
    "    for i in range(1, epochs+1):\n",
    "        idx = np.arange(n) #generate indeks data 1,2,3,4,...\n",
    "        if shuffle:\n",
    "            rng.shuffle(idx) #indeks di-shuffle 59, 21, 56, 18,...\n",
    "\n",
    "        # --- iterasi per mini-batch ---\n",
    "        for start in range(0, n, 1):\n",
    "            batch_idx = idx[start:start + 1] #ngambil 50 index \n",
    "            Xb = X[:, batch_idx]\n",
    "            Yb = Y[:, batch_idx] if Y.ndim == 2 else Y[batch_idx]  # sesuaikan bentuk\n",
    "\n",
    "            Z1, A1, Z2, A2 = forward(W1, b1, W2, b2, Xb, activation = activation)\n",
    "            dW1, db1, dW2, db2 = backpropagation(Z1, A1, Z2, A2, W2, Xb, Yb, activation = activation)\n",
    "            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, lr)\n",
    "\n",
    "        # --- monitoring loss/metric per i (pakai full data) ---\n",
    "        if (i % 10) == 0:\n",
    "            _, _, _, A2_train = forward(W1, b1, W2, b2, X, activation = activation)\n",
    "            _, _, _, A2_val = forward(W1, b1, W2, b2, X_val_array, activation=activation)\n",
    "            \n",
    "            pred_val = get_prediction(A2_val)\n",
    "            val_mae = get_error(pred_val, Y_val_array, loss=\"mae\")\n",
    "\n",
    "            pred_train = get_prediction(A2_train)\n",
    "            train_mae = get_error(pred_train, Y, loss=\"mae\")\n",
    "            print(f\"Epoch {i:4d} | Val error = {val_mae:.4f} | Train error = {train_mae:.4f}\")\n",
    "\n",
    "    experiments = []\n",
    "    experiments.append({\n",
    "        \"mode\" : \"Stoch_Batch_Gradient_Descent\",\n",
    "        \"weight initialization\" : winit,\n",
    "        \"activation\" : activation,\n",
    "        \"learning_rate\" : lr,\n",
    "        \"train_mae\" : float(train_mae), \n",
    "        \"val_mae\" : float(val_mae), \n",
    "    })\n",
    "\n",
    "    results_df = pd.DataFrame(experiments)\n",
    "\n",
    "    # save results\n",
    "    results_csv = \"results3.csv\"\n",
    "    if not os.path.isfile(results_csv):\n",
    "        results_df.to_csv(results_csv, index=False, mode='w', header=True)\n",
    "    else:\n",
    "        results_df.to_csv(results_csv, index=False, mode='a', header=False)\n",
    "    print(\"\\nAll experiments done. Results:\")\n",
    "\n",
    "    print(f\"\\nSaved results to {results_csv}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def mini_batch_gradient_descent(X, Y, epochs, lr, hidden_neuron, activation, winit, batch_size=1, shuffle=True, seed=42):\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    n = X.shape[1]  # jumlah record\n",
    "    input_dim = X.shape[0]\n",
    "    W1, b1, W2, b2 = init_params(input_dim, hidden_neuron, method=winit)\n",
    "\n",
    "    for i in range(1, epochs+1):\n",
    "        idx = np.arange(n) #generate indeks data 1,2,3,4,...\n",
    "        if shuffle:\n",
    "            rng.shuffle(idx) #indeks di-shuffle 59, 21, 56, 18,...\n",
    "\n",
    "        # --- iterasi per mini-batch ---\n",
    "        for start in range(0, n, batch_size):\n",
    "            batch_idx = idx[start:start + batch_size] #ngambil 50 index \n",
    "            Xb = X[:, batch_idx]\n",
    "            Yb = Y[:, batch_idx] if Y.ndim == 2 else Y[batch_idx]  # sesuaikan bentuk\n",
    "\n",
    "            Z1, A1, Z2, A2 = forward(W1, b1, W2, b2, Xb, activation)\n",
    "            dW1, db1, dW2, db2 = backpropagation(Z1, A1, Z2, A2, W2, Xb, Yb, activation)\n",
    "            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, lr)\n",
    "\n",
    "        # --- monitoring loss/metric per i (pakai full data) ---\n",
    "        if (i % 10) == 0:\n",
    "            _, _, _, A2_train = forward(W1, b1, W2, b2, X, activation = activation)\n",
    "            _, _, _, A2_val = forward(W1, b1, W2, b2, X_val_array, activation=activation)\n",
    "            pred_val = get_prediction(A2_val)\n",
    "            val_mae = get_error(pred_val, Y_val_array, loss=\"mae\")\n",
    "\n",
    "            pred_train = get_prediction(A2_train)\n",
    "            train_mae = get_error(pred_train, Y, loss=\"mae\")\n",
    "            print(f\"Epoch {i:4d} | Val error = {val_mae:.4f} | Train error = {train_mae:.4f}\")\n",
    "\n",
    "    experiments = []\n",
    "    experiments.append({\n",
    "        \"mode\" : \"Mini_Batch_Gradient_Descent\",\n",
    "        \"weight initialization\" : winit,\n",
    "        \"activation\" : activation,\n",
    "        \"learning_rate\" : lr,\n",
    "        \"train_mae\" : float(train_mae), \n",
    "        \"val_mae\" : float(val_mae), \n",
    "    })\n",
    "\n",
    "    results_df = pd.DataFrame(experiments)\n",
    "\n",
    "    # save results\n",
    "    results_csv = \"results3.csv\"\n",
    "    if not os.path.isfile(results_csv):\n",
    "        results_df.to_csv(results_csv, index=False, mode='w', header=True)\n",
    "    else:\n",
    "        results_df.to_csv(results_csv, index=False, mode='a', header=False)\n",
    "    print(\"\\nAll experiments done. Results:\")\n",
    "    print(f\"\\nSaved results to {results_csv}\")\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab96bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X, Y, epochs, lr, hidden_neuron, shuffle=True, seed=42, activation='relu', winit='xavier', type='batch', batch_size=None):\n",
    "    if type == 'batch':\n",
    "        if activation == 'tanh':\n",
    "            W1, b1, W2, b2 = batch_gradient_descent(X, Y, epochs, lr, hidden_neuron, 'tanh', winit=winit)\n",
    "        elif activation == 'leaky_relu':\n",
    "            W1, b1, W2, b2 = batch_gradient_descent(X, Y, epochs, lr, hidden_neuron, 'leaky_relu', winit=winit)\n",
    "        else:\n",
    "            W1, b1, W2, b2 = batch_gradient_descent(X, Y, epochs, lr, hidden_neuron, 'relu', winit=winit)\n",
    "    elif type == 'stoch':\n",
    "        if activation == 'tanh':\n",
    "            W1, b1, W2, b2 = stoch_gradient_descent(X, Y, hidden_neuron=hidden_neuron, epochs=epochs, winit=winit, activation='tanh', lr=lr)\n",
    "        elif activation == 'leaky_relu':\n",
    "            W1, b1, W2, b2 = stoch_gradient_descent(X, Y, hidden_neuron=hidden_neuron, epochs=epochs, winit=winit, activation='leaky_relu', lr=lr)\n",
    "        else:\n",
    "            W1, b1, W2, b2 = stoch_gradient_descent(X, Y, hidden_neuron=hidden_neuron, epochs=epochs, winit=winit, activation='relu', lr=lr)\n",
    "    elif type == 'mini_batch':\n",
    "        if activation == 'tanh':\n",
    "            W1, b1, W2, b2 = mini_batch_gradient_descent(X, Y, hidden_neuron=hidden_neuron,activation='tanh', winit=winit, epochs=epochs, lr=lr, batch_size=batch_size)\n",
    "        elif activation == 'leaky_relu':\n",
    "            W1, b1, W2, b2 = mini_batch_gradient_descent(X, Y, hidden_neuron=hidden_neuron,activation='leaky_relu', winit=winit, epochs=epochs, lr=lr,batch_size=batch_size)\n",
    "        else:\n",
    "            W1, b1, W2, b2 = mini_batch_gradient_descent(X, Y, hidden_neuron=hidden_neuron,activation='relu', winit=winit, epochs=epochs, lr=lr,batch_size=batch_size)\n",
    "    else:\n",
    "        print(\"Undefined Type\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "370a3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   10 | Train error = 5720283.7254 | val error = 5432849.8951\n",
      "Iter   20 | Train error = 3688596.4149 | val error = 3512304.5193\n",
      "Iter   30 | Train error = 2834745.6747 | val error = 2842851.5509\n",
      "Iter   40 | Train error = 2520213.3928 | val error = 2606443.7462\n",
      "Iter   50 | Train error = 2407994.7337 | val error = 2525617.8587\n",
      "Iter   60 | Train error = 2360592.7304 | val error = 2498485.8573\n",
      "Iter   70 | Train error = 2338671.9612 | val error = 2483049.3631\n",
      "Iter   80 | Train error = 2326320.5858 | val error = 2470162.8152\n",
      "Iter   90 | Train error = 2317091.8672 | val error = 2458838.0988\n",
      "Iter  100 | Train error = 2308078.2373 | val error = 2448487.0207\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Iter   10 | Train error = 4024408.9227 | val error = 3924394.0369\n",
      "Iter   20 | Train error = 3826080.9818 | val error = 3863416.0896\n",
      "Iter   30 | Train error = 3695006.7142 | val error = 3807060.2841\n",
      "Iter   40 | Train error = 3602779.6000 | val error = 3754437.1606\n",
      "Iter   50 | Train error = 3534070.6513 | val error = 3704857.9808\n",
      "Iter   60 | Train error = 3479836.5643 | val error = 3657839.5139\n",
      "Iter   70 | Train error = 3436376.7169 | val error = 3619582.5182\n",
      "Iter   80 | Train error = 3399128.6809 | val error = 3589252.4735\n",
      "Iter   90 | Train error = 3363951.2568 | val error = 3557120.6122\n",
      "Iter  100 | Train error = 3330511.4385 | val error = 3523753.4385\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Iter   10 | Train error = 5030416.2107 | val error = 4660127.5714\n",
      "Iter   20 | Train error = 3348381.9452 | val error = 3229848.7994\n",
      "Iter   30 | Train error = 2704914.0576 | val error = 2811723.7614\n",
      "Iter   40 | Train error = 2475958.2193 | val error = 2663882.7116\n",
      "Iter   50 | Train error = 2394452.5764 | val error = 2585105.2527\n",
      "Iter   60 | Train error = 2357616.7465 | val error = 2559419.8917\n",
      "Iter   70 | Train error = 2335631.7284 | val error = 2542982.9853\n",
      "Iter   80 | Train error = 2319984.6427 | val error = 2528837.7350\n",
      "Iter   90 | Train error = 2305590.9219 | val error = 2516106.6850\n",
      "Iter  100 | Train error = 2292137.4360 | val error = 2504274.0538\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n"
     ]
    }
   ],
   "source": [
    "#batch gradient descent relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='relu',winit='he',type='batch')\n",
    "#batch gradient descent tanh\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='tanh',winit='he',type='batch')\n",
    "#batch gradient descent leaky_relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='leaky_relu',winit='he',type='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbbeaa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   10 | Val error = 1237698.2427 | Train error = 1313555.8520\n",
      "Epoch   20 | Val error = 1006250.2590 | Train error = 1100657.4648\n",
      "Epoch   30 | Val error = 942654.8513 | Train error = 1010995.6026\n",
      "Epoch   40 | Val error = 875936.7089 | Train error = 937201.7431\n",
      "Epoch   50 | Val error = 914356.4044 | Train error = 947565.6043\n",
      "Epoch   60 | Val error = 866436.4152 | Train error = 885653.0171\n",
      "Epoch   70 | Val error = 831668.9828 | Train error = 845962.7006\n",
      "Epoch   80 | Val error = 823191.5601 | Train error = 828949.1906\n",
      "Epoch   90 | Val error = 816345.2641 | Train error = 814614.3038\n",
      "Epoch  100 | Val error = 804579.3286 | Train error = 800370.8318\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Epoch   10 | Val error = 1385006.2249 | Train error = 1434936.3127\n",
      "Epoch   20 | Val error = 1171711.4898 | Train error = 1221192.5145\n",
      "Epoch   30 | Val error = 1102893.6797 | Train error = 1149880.2525\n",
      "Epoch   40 | Val error = 1039272.2353 | Train error = 1082791.1549\n",
      "Epoch   50 | Val error = 1011688.5549 | Train error = 1068354.8769\n",
      "Epoch   60 | Val error = 946229.1313 | Train error = 1009454.0191\n",
      "Epoch   70 | Val error = 912725.6380 | Train error = 980698.0949\n",
      "Epoch   80 | Val error = 894021.5335 | Train error = 960368.9037\n",
      "Epoch   90 | Val error = 869748.7366 | Train error = 940721.6997\n",
      "Epoch  100 | Val error = 861212.5766 | Train error = 924365.2691\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Epoch   10 | Val error = 1212577.1318 | Train error = 1266078.2404\n",
      "Epoch   20 | Val error = 1017652.0949 | Train error = 1082578.9230\n",
      "Epoch   30 | Val error = 946149.0488 | Train error = 1008921.0890\n",
      "Epoch   40 | Val error = 880357.5444 | Train error = 936223.7305\n",
      "Epoch   50 | Val error = 908014.5578 | Train error = 949305.0128\n",
      "Epoch   60 | Val error = 865701.9516 | Train error = 885849.2544\n",
      "Epoch   70 | Val error = 826618.9290 | Train error = 848844.4466\n",
      "Epoch   80 | Val error = 817463.8260 | Train error = 831279.7590\n",
      "Epoch   90 | Val error = 808014.3882 | Train error = 819500.0376\n",
      "Epoch  100 | Val error = 801096.9587 | Train error = 809135.8958\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n"
     ]
    }
   ],
   "source": [
    "#Stcoh gradient descent relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='relu', winit='he',type='stoch')\n",
    "#tanh\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='tanh',winit='he',type='stoch')\n",
    "#leaky relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='leaky_relu',winit='he',type='stoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d463e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   10 | Val error = 2470606.0327 | Train error = 2325617.2035\n",
      "Epoch   20 | Val error = 2394917.6067 | Train error = 2254857.5965\n",
      "Epoch   30 | Val error = 2330021.8015 | Train error = 2195543.2787\n",
      "Epoch   40 | Val error = 2277910.3723 | Train error = 2142155.7245\n",
      "Epoch   50 | Val error = 2229877.2355 | Train error = 2098192.5798\n",
      "Epoch   60 | Val error = 2184686.6980 | Train error = 2055124.9486\n",
      "Epoch   70 | Val error = 2141979.8418 | Train error = 2018917.9812\n",
      "Epoch   80 | Val error = 2101943.7904 | Train error = 1984886.1742\n",
      "Epoch   90 | Val error = 2063454.7038 | Train error = 1951605.8026\n",
      "Epoch  100 | Val error = 2026495.9903 | Train error = 1921969.1478\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Epoch   10 | Val error = 3589458.1999 | Train error = 3395354.6737\n",
      "Epoch   20 | Val error = 3338679.6280 | Train error = 3145899.7170\n",
      "Epoch   30 | Val error = 3114400.2131 | Train error = 2942111.8776\n",
      "Epoch   40 | Val error = 2918564.6341 | Train error = 2771234.2154\n",
      "Epoch   50 | Val error = 2747355.7395 | Train error = 2629191.6917\n",
      "Epoch   60 | Val error = 2594049.2370 | Train error = 2510477.1922\n",
      "Epoch   70 | Val error = 2466861.1640 | Train error = 2411668.1757\n",
      "Epoch   80 | Val error = 2370436.7771 | Train error = 2330293.5956\n",
      "Epoch   90 | Val error = 2281365.1131 | Train error = 2259094.6630\n",
      "Epoch  100 | Val error = 2201966.6200 | Train error = 2198623.0139\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n",
      "Epoch   10 | Val error = 2529197.0691 | Train error = 2318822.2314\n",
      "Epoch   20 | Val error = 2441430.8320 | Train error = 2219075.2909\n",
      "Epoch   30 | Val error = 2366376.2809 | Train error = 2143168.7018\n",
      "Epoch   40 | Val error = 2301464.3474 | Train error = 2081844.0994\n",
      "Epoch   50 | Val error = 2241887.2996 | Train error = 2032320.0878\n",
      "Epoch   60 | Val error = 2189823.1003 | Train error = 1985372.6600\n",
      "Epoch   70 | Val error = 2143544.0198 | Train error = 1946426.1792\n",
      "Epoch   80 | Val error = 2100729.3186 | Train error = 1911006.5101\n",
      "Epoch   90 | Val error = 2060219.3322 | Train error = 1877097.8556\n",
      "Epoch  100 | Val error = 2021623.8576 | Train error = 1846773.8881\n",
      "\n",
      "All experiments done. Results:\n",
      "\n",
      "Saved results to results3.csv\n"
     ]
    }
   ],
   "source": [
    "#mini batch gradient descent relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='relu', winit='he',type='mini_batch', batch_size=50)\n",
    "#tanh\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='tanh',winit='he',type='mini_batch', batch_size=50)\n",
    "#leaky relu\n",
    "run(X_train_array, Y_train_array, 100, 0.001, 32, activation='leaky_relu',winit='he',type='mini_batch', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8cb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
