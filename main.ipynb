{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d222a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_from_scratch_experiments.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "CSV_PATH = \"Housing.csv\"   # ubah ke path file jika perlu\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# NN hyperparams (default, bisa diubah)\n",
    "INPUT_NEURONS = None   # diisi setelah preprocessing (fitur)\n",
    "HIDDEN_NEURONS = 64\n",
    "OUTPUT_NEURONS = 1\n",
    "LEARNING_RATE = 0.01\n",
    "MAX_EPOCHS = 100       # batasi supaya cepat\n",
    "MINIBATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af809c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Utility metrics\n",
    "# ----------------------------\n",
    "def mse_loss(y_pred, y_true):\n",
    "    # y_pred, y_true shape (n_samples, 1)\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def mae_loss(y_pred, y_true):\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "def mse_grad(y_pred, y_true):\n",
    "    # derivative per sample: 2*(y_pred - y_true) / n\n",
    "    n = y_true.shape[0]\n",
    "    return (2.0 / n) * (y_pred - y_true)\n",
    "\n",
    "def mae_grad(y_pred, y_true, eps=1e-8):\n",
    "    # derivative of |e| is sign(e). To avoid nan at zero, add eps\n",
    "    n = y_true.shape[0]\n",
    "    diff = y_pred - y_true\n",
    "    grad = np.sign(diff)\n",
    "    # if diff == 0, sign gives 0 â€” it's fine. normalize by n\n",
    "    return (1.0 / n) * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Neural network (from scratch)\n",
    "# ----------------------------\n",
    "class SimpleMLP:\n",
    "    def __init__(self, input_dim, hidden_dim=64, output_dim=1, init_scale=0.01, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # weights: random normal (user requested random normal)\n",
    "        # W1 shape (hidden_dim, input_dim)\n",
    "        #(baris, kolom)\n",
    "        self.W1 = np.random.randn(self.hidden_dim, self.input_dim) * init_scale\n",
    "        # b1 shape (hidden_dim, 1)\n",
    "        self.b1 = np.zeros((self.hidden_dim, 1))\n",
    "\n",
    "        # W2 shape (output_dim, hidden_dim)\n",
    "        self.W2 = np.random.randn(self.output_dim, self.hidden_dim) * init_scale\n",
    "        # b2 shape (output_dim, 1)\n",
    "        self.b2 = np.zeros((self.output_dim, 1))\n",
    "\n",
    "    # activation: ReLU & its derivative\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_grad(z):\n",
    "        return (z > 0).astype(float)\n",
    "\n",
    "    # forward pass: x shape (n_samples, input_dim)\n",
    "    def forward(self, x):\n",
    "        self.x = x.T\n",
    "\n",
    "        self.z1 = self.W1.dot(self.x) + self.b1 #sum dari masing masing neuron hidden layer, sum h1,sum h2...\n",
    "        self.a1 = self.relu(self.z1)   # output dari masing masing hidden neuron, ex: output h1,output h2...\n",
    "\n",
    "        self.z2 = self.W2.dot(self.a1) + self.b2 #sum dari masing masing neuron output layer, sum 01,sum 02...\n",
    "        self.a2 = self.z2.T # output dari masing masing output neuron, ex: output 01,output 02...\n",
    "        # we'll return (n, output_dim) as predictions (linear output)\n",
    "\n",
    "        return self.a2 #a2 ini udah hasil prediksi\n",
    "\n",
    "    # backward: compute gradients given y_true and loss type\n",
    "    # y_true shape (n_samples, output_dim)\n",
    "    def backward(self, y_true, loss_type=\"mse\"):\n",
    "        n = y_true.shape[0]\n",
    "        # predictions shape (n, output_dim)\n",
    "        y_pred = self.a2  # (n, output_dim)\n",
    "        # Convert to shape (output_dim, n)\n",
    "        y_pred_T = y_pred.T  # (output_dim, n)\n",
    "        y_true_T = y_true.T  # (output_dim, n)\n",
    "\n",
    "        # compute dL/dy_pred / error di output\n",
    "        if loss_type == \"mse\":\n",
    "            dL_da2 = (2.0 / n) * (y_pred_T - y_true_T)\n",
    "        elif loss_type == \"mae\":\n",
    "            dL_da2 = (1.0 / n) * np.sign(y_pred_T - y_true_T)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown loss_type\")\n",
    "\n",
    "        # For linear output, derivative of z2 is 1: dL/dz2 = dL/da2\n",
    "        dZ2 = dL_da2   # shape (output_dim, n)\n",
    "\n",
    "        # gradients for W2 and b2\n",
    "        dW2 = dZ2.dot(self.a1.T)   # (output_dim, n) @ (n, hidden_dim) -> (output_dim, hidden_dim)\n",
    "        db2 = np.sum(dZ2, axis=1, keepdims=True)  # (output_dim, 1)\n",
    "\n",
    "        # propagate to hidden: dA1 = W2^T @ dZ2\n",
    "        dA1 = self.W2.T.dot(dZ2)   # (hidden_dim, n)    \n",
    "\n",
    "        # dZ1 = dA1 * relu_grad(z1)\n",
    "        dZ1 = dA1 * self.relu_grad(self.z1)   # (hidden_dim, n)\n",
    "\n",
    "        # gradients for W1 and b1\n",
    "        dW1 = dZ1.dot(self.x.T)  # (hidden_dim, n) @ (n, input_dim) -> (hidden_dim, input_dim)\n",
    "        db1 = np.sum(dZ1, axis=1, keepdims=True)  # (hidden_dim, 1)\n",
    "\n",
    "        # store grads\n",
    "        grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "        return grads\n",
    "\n",
    "    # update weights with grads\n",
    "    def apply_grads(self, grads, lr=0.01):\n",
    "        self.W1 -= lr * grads[\"dW1\"]\n",
    "        self.b1 -= lr * grads[\"db1\"]\n",
    "        self.W2 -= lr * grads[\"dW2\"]\n",
    "        self.b2 -= lr * grads[\"db2\"]\n",
    "\n",
    "    # predict wrapper (array shape (n_samples, output_dim))\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ce0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training function supporting batch/stochastic/minibatch\n",
    "# ----------------------------\n",
    "def train_model(model, X_train, y_train, X_val, y_val,\n",
    "                loss_type=\"mse\",\n",
    "                mode=\"batch\",\n",
    "                lr=0.01,\n",
    "                max_epochs=100,\n",
    "                minibatch_size=32,\n",
    "                verbose=False):\n",
    "    n_samples = X_train.shape[0]\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # For stochastic and minibatch, shuffle each epoch\n",
    "        perm = np.arange(n_samples)\n",
    "        if mode in (\"stochastic\", \"minibatch\"):\n",
    "            np.random.shuffle(perm)\n",
    "\n",
    "        if mode == \"batch\":\n",
    "            # forward on whole train set\n",
    "            preds = model.forward(X_train)   # (n, 1)\n",
    "            # compute grads from entire batch\n",
    "            grads = model.backward(y_train, loss_type=loss_type)\n",
    "            model.apply_grads(grads, lr=lr)\n",
    "\n",
    "            # compute train loss\n",
    "            if loss_type == \"mse\":\n",
    "                train_loss = mse_loss(preds, y_train)\n",
    "            else:\n",
    "                train_loss = mae_loss(preds, y_train)\n",
    "\n",
    "        elif mode == \"stochastic\":\n",
    "            # update per sample\n",
    "            total_loss = 0.0\n",
    "            for i in perm:\n",
    "                x_i = X_train[i:i+1]    # shape (1, d)\n",
    "                y_i = y_train[i:i+1]    # shape (1, 1)\n",
    "                preds_i = model.forward(x_i)\n",
    "                grads = model.backward(y_i, loss_type=loss_type)\n",
    "                model.apply_grads(grads, lr=lr)\n",
    "                # accumulate loss\n",
    "                if loss_type == \"mse\":\n",
    "                    total_loss += mse_loss(preds_i, y_i)\n",
    "                else:\n",
    "                    total_loss += mae_loss(preds_i, y_i)\n",
    "            train_loss = total_loss / n_samples\n",
    "\n",
    "        elif mode == \"minibatch\":\n",
    "            total_loss = 0.0\n",
    "            for start in range(0, n_samples, minibatch_size):\n",
    "                idx = perm[start:start+minibatch_size]\n",
    "                x_b = X_train[idx]\n",
    "                y_b = y_train[idx]\n",
    "                preds_b = model.forward(x_b)\n",
    "                grads = model.backward(y_b, loss_type=loss_type)\n",
    "                model.apply_grads(grads, lr=lr)\n",
    "                if loss_type == \"mse\":\n",
    "                    total_loss += mse_loss(preds_b, y_b) * len(idx)\n",
    "                else:\n",
    "                    total_loss += mae_loss(preds_b, y_b) * len(idx)\n",
    "            train_loss = total_loss / n_samples\n",
    "        else:\n",
    "            raise ValueError(\"Unknown training mode\")\n",
    "\n",
    "        # validation loss (MSE and MAE for monitoring)\n",
    "        val_pred = model.predict(X_val)\n",
    "        val_mse = mse_loss(val_pred, y_val)\n",
    "        val_mae = mae_loss(val_pred, y_val)\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_mse\"].append(val_mse)\n",
    "        history[\"val_mae\"].append(val_mae)\n",
    "\n",
    "        if verbose and (epoch % max(1, max_epochs // 5) == 0 or epoch == 1):\n",
    "            print(f\"Epoch {epoch}/{max_epochs} | train({loss_type})={train_loss:.4f} | val_mse={val_mse:.4f} val_mae={val_mae:.4f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c274392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Data loading & preprocessing\n",
    "# ----------------------------\n",
    "def load_and_preprocess(csv_path, scale_target=True):\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"CSV not found at {csv_path}. Please place the Kaggle 'Housing.csv' there.\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # pastikan kolom target ada\n",
    "    if \"price\" not in df.columns and \"Price\" in df.columns:\n",
    "        df = df.rename(columns={\"Price\": \"price\"})\n",
    "    if \"price\" not in df.columns:\n",
    "        raise ValueError(\"Target column 'price' not found in CSV.\")\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # --- Pisahkan target & fitur ---\n",
    "    y = df[[\"price\"]].astype(float).values\n",
    "    X = df.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "    # --- Definisi kolom ---\n",
    "    binary_cols = [\n",
    "        \"mainroad\",\n",
    "        \"guestroom\",\n",
    "        \"basement\",\n",
    "        \"hotwaterheating\",\n",
    "        \"airconditioning\",\n",
    "        \"prefarea\",\n",
    "    ]\n",
    "    multi_cols = [\"furnishingstatus\"]\n",
    "    # kolom numerik asli (pastikan sesuai dataset)\n",
    "    num_cols = [\"area\", \"bedrooms\", \"bathrooms\", \"stories\", \"parking\"]\n",
    "\n",
    "    # --- Encode kolom binary (yes/no -> 1/0) ---\n",
    "    for col in binary_cols:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "    # --- One-hot furnishingstatus ---\n",
    "    if all(col in X.columns for col in multi_cols):\n",
    "        enc = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "        onehot = enc.fit_transform(X[multi_cols])\n",
    "        onehot_df = pd.DataFrame(\n",
    "            onehot, columns=enc.get_feature_names_out(multi_cols), index=X.index\n",
    "        )\n",
    "        X = pd.concat([X.drop(columns=multi_cols), onehot_df], axis=1)\n",
    "\n",
    "    # --- Scaling numerik ---\n",
    "    scaler_X = StandardScaler()\n",
    "    X[num_cols] = scaler_X.fit_transform(X[num_cols])\n",
    "\n",
    "    # --- Scaling target (opsional) ---\n",
    "    if scale_target:\n",
    "        scaler_y = StandardScaler()\n",
    "        y = scaler_y.fit_transform(y)\n",
    "    else:\n",
    "        scaler_y = None\n",
    "\n",
    "    print(\"INI Y: \",y)\n",
    "\n",
    "    return X.values.astype(float), y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ed87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Running experiments (2 losses x 3 modes)\n",
    "# ----------------------------\n",
    "def run_experiments(csv_path,\n",
    "                    hidden_neurons=HIDDEN_NEURONS,\n",
    "                    lr=LEARNING_RATE,\n",
    "                    max_epochs=MAX_EPOCHS,\n",
    "                    minibatch_size=MINIBATCH_SIZE,\n",
    "                    random_seed=RANDOM_SEED):\n",
    "    X, y = load_and_preprocess(csv_path)\n",
    "    # split 80:20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    # also split validation from train (10% of train)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=random_seed)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    experiments = []\n",
    "    modes = [\"batch\", \"stochastic\", \"minibatch\"]\n",
    "    losses = [\"mse\", \"mae\"]\n",
    "\n",
    "    for loss_type in losses:\n",
    "        for mode in modes:\n",
    "            print(f\"\\n=== Running: loss={loss_type} | mode={mode} ===\")\n",
    "            # recreate model per experiment (fresh weights)\n",
    "            model = SimpleMLP(input_dim=input_dim, hidden_dim=hidden_neurons, output_dim=1, init_scale=0.1, seed=random_seed)\n",
    "\n",
    "            t0 = time.time()\n",
    "            history = train_model(model, X_train, y_train, X_val, y_val,\n",
    "                                  loss_type=loss_type,\n",
    "                                  mode=mode,\n",
    "                                  lr=lr,\n",
    "                                  max_epochs=max_epochs,\n",
    "                                  minibatch_size=minibatch_size,\n",
    "                                  verbose=True)\n",
    "            t1 = time.time()\n",
    "\n",
    "            # evaluate on test set\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            test_mse = mse_loss(y_pred_test, y_test)\n",
    "            test_mae = mae_loss(y_pred_test, y_test)\n",
    "\n",
    "            experiments.append({\n",
    "                \"loss_used_for_training\": loss_type,\n",
    "                \"mode\": mode,\n",
    "                \"test_mse\": float(test_mse),\n",
    "                \"test_mae\": float(test_mae),\n",
    "                \"train_time_sec\": round(t1 - t0, 2)\n",
    "            })\n",
    "\n",
    "            # optional: store final metrics\n",
    "            print(f\"Finished: loss={loss_type} mode={mode} | test_mse={test_mse:.4f} test_mae={test_mae:.4f} time={t1-t0:.2f}s\")\n",
    "\n",
    "    results_df = pd.DataFrame(experiments)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9463ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments...\n",
      "INI Y:  [[ 4.56636513e+00]\n",
      " [ 4.00448405e+00]\n",
      " [ 4.00448405e+00]\n",
      " [ 3.98575468e+00]\n",
      " [ 3.55497918e+00]\n",
      " [ 3.25530927e+00]\n",
      " [ 2.88072189e+00]\n",
      " [ 2.88072189e+00]\n",
      " [ 2.73088693e+00]\n",
      " [ 2.69342819e+00]\n",
      " [ 2.69342819e+00]\n",
      " [ 2.62974834e+00]\n",
      " [ 2.43121702e+00]\n",
      " [ 2.39375829e+00]\n",
      " [ 2.39375829e+00]\n",
      " [ 2.31884081e+00]\n",
      " [ 2.31884081e+00]\n",
      " [ 2.24392333e+00]\n",
      " [ 2.20646459e+00]\n",
      " [ 2.18773522e+00]\n",
      " [ 2.13154711e+00]\n",
      " [ 2.09408838e+00]\n",
      " [ 2.07535901e+00]\n",
      " [ 2.07535901e+00]\n",
      " [ 2.03790027e+00]\n",
      " [ 2.01917090e+00]\n",
      " [ 1.97796629e+00]\n",
      " [ 1.94425342e+00]\n",
      " [ 1.94425342e+00]\n",
      " [ 1.94425342e+00]\n",
      " [ 1.94425342e+00]\n",
      " [ 1.94425342e+00]\n",
      " [ 1.88806531e+00]\n",
      " [ 1.83187721e+00]\n",
      " [ 1.79441847e+00]\n",
      " [ 1.77351649e+00]\n",
      " [ 1.75321385e+00]\n",
      " [ 1.71950099e+00]\n",
      " [ 1.71013630e+00]\n",
      " [ 1.68204225e+00]\n",
      " [ 1.66331288e+00]\n",
      " [ 1.64458351e+00]\n",
      " [ 1.56966604e+00]\n",
      " [ 1.56966604e+00]\n",
      " [ 1.49474856e+00]\n",
      " [ 1.49474856e+00]\n",
      " [ 1.47601919e+00]\n",
      " [ 1.45728982e+00]\n",
      " [ 1.43856045e+00]\n",
      " [ 1.41983108e+00]\n",
      " [ 1.41983108e+00]\n",
      " [ 1.41983108e+00]\n",
      " [ 1.38237234e+00]\n",
      " [ 1.38237234e+00]\n",
      " [ 1.38237234e+00]\n",
      " [ 1.38237234e+00]\n",
      " [ 1.37862647e+00]\n",
      " [ 1.32618423e+00]\n",
      " [ 1.30745486e+00]\n",
      " [ 1.30745486e+00]\n",
      " [ 1.26999613e+00]\n",
      " [ 1.23253739e+00]\n",
      " [ 1.23253739e+00]\n",
      " [ 1.21380802e+00]\n",
      " [ 1.19507865e+00]\n",
      " [ 1.15761991e+00]\n",
      " [ 1.15761991e+00]\n",
      " [ 1.13889054e+00]\n",
      " [ 1.12016117e+00]\n",
      " [ 1.08270243e+00]\n",
      " [ 1.08270243e+00]\n",
      " [ 1.06397306e+00]\n",
      " [ 1.04524369e+00]\n",
      " [ 1.02651432e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 1.00778496e+00]\n",
      " [ 9.96547334e-01]\n",
      " [ 9.89055586e-01]\n",
      " [ 9.89055586e-01]\n",
      " [ 9.70326217e-01]\n",
      " [ 9.32867478e-01]\n",
      " [ 9.32867478e-01]\n",
      " [ 9.32867478e-01]\n",
      " [ 9.14138109e-01]\n",
      " [ 9.14138109e-01]\n",
      " [ 8.95408740e-01]\n",
      " [ 8.95408740e-01]\n",
      " [ 8.84171118e-01]\n",
      " [ 8.76679370e-01]\n",
      " [ 8.20491262e-01]\n",
      " [ 8.20491262e-01]\n",
      " [ 8.20491262e-01]\n",
      " [ 8.20491262e-01]\n",
      " [ 8.20491262e-01]\n",
      " [ 8.16745389e-01]\n",
      " [ 8.01761893e-01]\n",
      " [ 7.83032524e-01]\n",
      " [ 7.83032524e-01]\n",
      " [ 7.64303154e-01]\n",
      " [ 7.64303154e-01]\n",
      " [ 7.64303154e-01]\n",
      " [ 7.45573785e-01]\n",
      " [ 7.45573785e-01]\n",
      " [ 7.26844416e-01]\n",
      " [ 7.17479731e-01]\n",
      " [ 7.08115046e-01]\n",
      " [ 7.08115046e-01]\n",
      " [ 7.08115046e-01]\n",
      " [ 7.04369173e-01]\n",
      " [ 7.04369173e-01]\n",
      " [ 6.70656308e-01]\n",
      " [ 6.70656308e-01]\n",
      " [ 6.70656308e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.33197569e-01]\n",
      " [ 6.29451695e-01]\n",
      " [ 5.95738831e-01]\n",
      " [ 5.95738831e-01]\n",
      " [ 5.91992957e-01]\n",
      " [ 5.91992957e-01]\n",
      " [ 5.88247083e-01]\n",
      " [ 5.58280092e-01]\n",
      " [ 5.58280092e-01]\n",
      " [ 5.58280092e-01]\n",
      " [ 5.54534218e-01]\n",
      " [ 5.39550723e-01]\n",
      " [ 5.20821353e-01]\n",
      " [ 5.20821353e-01]\n",
      " [ 5.20821353e-01]\n",
      " [ 5.20821353e-01]\n",
      " [ 5.20821353e-01]\n",
      " [ 4.73997930e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.45903876e-01]\n",
      " [ 4.27174507e-01]\n",
      " [ 4.27174507e-01]\n",
      " [ 4.08445137e-01]\n",
      " [ 4.08445137e-01]\n",
      " [ 4.08445137e-01]\n",
      " [ 4.04699264e-01]\n",
      " [ 3.89715768e-01]\n",
      " [ 3.89715768e-01]\n",
      " [ 3.70986399e-01]\n",
      " [ 3.70986399e-01]\n",
      " [ 3.70986399e-01]\n",
      " [ 3.70986399e-01]\n",
      " [ 3.52257029e-01]\n",
      " [ 3.33527660e-01]\n",
      " [ 3.29781786e-01]\n",
      " [ 2.96068921e-01]\n",
      " [ 2.77339552e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.58610183e-01]\n",
      " [ 2.54864309e-01]\n",
      " [ 2.47372561e-01]\n",
      " [ 2.39880814e-01]\n",
      " [ 2.39880814e-01]\n",
      " [ 2.39880814e-01]\n",
      " [ 2.02422075e-01]\n",
      " [ 2.02422075e-01]\n",
      " [ 1.83692706e-01]\n",
      " [ 1.83692706e-01]\n",
      " [ 1.83692706e-01]\n",
      " [ 1.83692706e-01]\n",
      " [ 1.64963336e-01]\n",
      " [ 1.46233967e-01]\n",
      " [ 1.46233967e-01]\n",
      " [ 1.46233967e-01]\n",
      " [ 1.46233967e-01]\n",
      " [ 1.42488093e-01]\n",
      " [ 1.27504598e-01]\n",
      " [ 1.08775228e-01]\n",
      " [ 1.08775228e-01]\n",
      " [ 1.01283481e-01]\n",
      " [ 9.00458590e-02]\n",
      " [ 7.50623635e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 7.13164897e-02]\n",
      " [ 6.75706158e-02]\n",
      " [ 6.75706158e-02]\n",
      " [ 5.25871204e-02]\n",
      " [ 3.38577510e-02]\n",
      " [ 3.38577510e-02]\n",
      " [ 3.38577510e-02]\n",
      " [ 3.38577510e-02]\n",
      " [ 1.51283817e-02]\n",
      " [ 1.51283817e-02]\n",
      " [ 1.44886277e-04]\n",
      " [-3.60098759e-03]\n",
      " [-3.60098759e-03]\n",
      " [-3.60098759e-03]\n",
      " [-7.34686145e-03]\n",
      " [-4.10597262e-02]\n",
      " [-4.10597262e-02]\n",
      " [-4.10597262e-02]\n",
      " [-4.10597262e-02]\n",
      " [-4.10597262e-02]\n",
      " [-4.10597262e-02]\n",
      " [-5.97890955e-02]\n",
      " [-7.85184649e-02]\n",
      " [-7.85184649e-02]\n",
      " [-7.85184649e-02]\n",
      " [-7.85184649e-02]\n",
      " [-7.85184649e-02]\n",
      " [-8.22643387e-02]\n",
      " [-9.72478342e-02]\n",
      " [-9.72478342e-02]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.15977203e-01]\n",
      " [-1.19723077e-01]\n",
      " [-1.19723077e-01]\n",
      " [-1.34706573e-01]\n",
      " [-1.34706573e-01]\n",
      " [-1.34706573e-01]\n",
      " [-1.34706573e-01]\n",
      " [-1.53435942e-01]\n",
      " [-1.53435942e-01]\n",
      " [-1.53435942e-01]\n",
      " [-1.53435942e-01]\n",
      " [-1.53435942e-01]\n",
      " [-1.57181816e-01]\n",
      " [-1.57181816e-01]\n",
      " [-1.57181816e-01]\n",
      " [-1.72165311e-01]\n",
      " [-1.90894681e-01]\n",
      " [-1.90894681e-01]\n",
      " [-1.94640555e-01]\n",
      " [-1.94640555e-01]\n",
      " [-1.94640555e-01]\n",
      " [-2.05878176e-01]\n",
      " [-2.09624050e-01]\n",
      " [-2.28353419e-01]\n",
      " [-2.28353419e-01]\n",
      " [-2.28353419e-01]\n",
      " [-2.28353419e-01]\n",
      " [-2.28353419e-01]\n",
      " [-2.39591041e-01]\n",
      " [-2.47082789e-01]\n",
      " [-2.47082789e-01]\n",
      " [-2.62066284e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.65812158e-01]\n",
      " [-2.84541527e-01]\n",
      " [-2.84541527e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.03270897e-01]\n",
      " [-3.07016771e-01]\n",
      " [-3.07016771e-01]\n",
      " [-3.22000266e-01]\n",
      " [-3.22000266e-01]\n",
      " [-3.22000266e-01]\n",
      " [-3.40729635e-01]\n",
      " [-3.40729635e-01]\n",
      " [-3.44475509e-01]\n",
      " [-3.57586068e-01]\n",
      " [-3.59459005e-01]\n",
      " [-3.59459005e-01]\n",
      " [-3.59459005e-01]\n",
      " [-3.78188374e-01]\n",
      " [-3.78188374e-01]\n",
      " [-3.78188374e-01]\n",
      " [-3.78188374e-01]\n",
      " [-3.78188374e-01]\n",
      " [-3.96917743e-01]\n",
      " [-3.96917743e-01]\n",
      " [-3.96917743e-01]\n",
      " [-4.06282428e-01]\n",
      " [-4.06282428e-01]\n",
      " [-4.15647113e-01]\n",
      " [-4.15647113e-01]\n",
      " [-4.15647113e-01]\n",
      " [-4.15647113e-01]\n",
      " [-4.15647113e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.53105851e-01]\n",
      " [-4.71835221e-01]\n",
      " [-4.71835221e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.90564590e-01]\n",
      " [-4.98056338e-01]\n",
      " [-5.09293959e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.28023328e-01]\n",
      " [-5.31769202e-01]\n",
      " [-5.31769202e-01]\n",
      " [-5.31769202e-01]\n",
      " [-5.46752698e-01]\n",
      " [-5.65482067e-01]\n",
      " [-5.65482067e-01]\n",
      " [-5.65482067e-01]\n",
      " [-5.65482067e-01]\n",
      " [-5.65482067e-01]\n",
      " [-5.69227941e-01]\n",
      " [-5.69227941e-01]\n",
      " [-5.84211436e-01]\n",
      " [-5.84211436e-01]\n",
      " [-5.84211436e-01]\n",
      " [-5.84211436e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.02940806e-01]\n",
      " [-6.06686680e-01]\n",
      " [-6.21670175e-01]\n",
      " [-6.21670175e-01]\n",
      " [-6.40399544e-01]\n",
      " [-6.40399544e-01]\n",
      " [-6.40399544e-01]\n",
      " [-6.40399544e-01]\n",
      " [-6.59128914e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.77858283e-01]\n",
      " [-6.81604157e-01]\n",
      " [-6.96587652e-01]\n",
      " [-6.96587652e-01]\n",
      " [-6.96587652e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.15317022e-01]\n",
      " [-7.19062896e-01]\n",
      " [-7.34046391e-01]\n",
      " [-7.34046391e-01]\n",
      " [-7.34046391e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.52775760e-01]\n",
      " [-7.56521634e-01]\n",
      " [-7.67759256e-01]\n",
      " [-7.71505130e-01]\n",
      " [-7.71505130e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-7.90234499e-01]\n",
      " [-8.08963868e-01]\n",
      " [-8.08963868e-01]\n",
      " [-8.20201490e-01]\n",
      " [-8.27693238e-01]\n",
      " [-8.27693238e-01]\n",
      " [-8.27693238e-01]\n",
      " [-8.27693238e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.65151976e-01]\n",
      " [-8.68897850e-01]\n",
      " [-8.76389598e-01]\n",
      " [-8.81821115e-01]\n",
      " [-8.83881346e-01]\n",
      " [-8.83881346e-01]\n",
      " [-8.83881346e-01]\n",
      " [-8.98864841e-01]\n",
      " [-9.02610715e-01]\n",
      " [-9.02610715e-01]\n",
      " [-9.02610715e-01]\n",
      " [-9.02610715e-01]\n",
      " [-9.21340084e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.40069453e-01]\n",
      " [-9.43815327e-01]\n",
      " [-9.58798823e-01]\n",
      " [-9.66290571e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-9.77528192e-01]\n",
      " [-1.01498693e+00]\n",
      " [-1.01498693e+00]\n",
      " [-1.01498693e+00]\n",
      " [-1.01498693e+00]\n",
      " [-1.02435162e+00]\n",
      " [-1.03371630e+00]\n",
      " [-1.03371630e+00]\n",
      " [-1.03371630e+00]\n",
      " [-1.05244567e+00]\n",
      " [-1.05244567e+00]\n",
      " [-1.08990441e+00]\n",
      " [-1.08990441e+00]\n",
      " [-1.10863378e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.12736315e+00]\n",
      " [-1.13110902e+00]\n",
      " [-1.13110902e+00]\n",
      " [-1.15733014e+00]\n",
      " [-1.16482189e+00]\n",
      " [-1.16482189e+00]\n",
      " [-1.16482189e+00]\n",
      " [-1.20228062e+00]\n",
      " [-1.20228062e+00]\n",
      " [-1.20228062e+00]\n",
      " [-1.22100999e+00]\n",
      " [-1.22100999e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.23973936e+00]\n",
      " [-1.26221461e+00]\n",
      " [-1.27719810e+00]\n",
      " [-1.27719810e+00]\n",
      " [-1.27719810e+00]\n",
      " [-1.29592747e+00]\n",
      " [-1.31465684e+00]\n",
      " [-1.33338621e+00]\n",
      " [-1.33338621e+00]\n",
      " [-1.33338621e+00]\n",
      " [-1.35211558e+00]\n",
      " [-1.35586145e+00]\n",
      " [-1.40830369e+00]\n",
      " [-1.42703306e+00]\n",
      " [-1.42703306e+00]\n",
      " [-1.42703306e+00]\n",
      " [-1.50195053e+00]\n",
      " [-1.53940927e+00]\n",
      " [-1.53940927e+00]\n",
      " [-1.55813864e+00]\n",
      " [-1.57686801e+00]\n",
      " [-1.60514936e+00]\n",
      " [-1.61432675e+00]\n",
      " [-1.61432675e+00]\n",
      " [-1.61432675e+00]]\n",
      "\n",
      "=== Running: loss=mse | mode=batch ===\n",
      "Epoch 1/100 | train(mse)=0.9538 | val_mse=0.5933 val_mae=0.6241\n",
      "Epoch 20/100 | train(mse)=0.6971 | val_mse=0.4223 val_mae=0.5159\n",
      "Epoch 40/100 | train(mse)=0.5423 | val_mse=0.3233 val_mae=0.4371\n",
      "Epoch 60/100 | train(mse)=0.4521 | val_mse=0.2697 val_mae=0.4002\n",
      "Epoch 80/100 | train(mse)=0.4031 | val_mse=0.2434 val_mae=0.3858\n",
      "Epoch 100/100 | train(mse)=0.3761 | val_mse=0.2310 val_mae=0.3792\n",
      "Finished: loss=mse mode=batch | test_mse=0.6944 test_mae=0.6071 time=0.31s\n",
      "\n",
      "=== Running: loss=mse | mode=stochastic ===\n",
      "Epoch 1/100 | train(mse)=0.4366 | val_mse=0.2277 val_mae=0.3418\n",
      "Epoch 20/100 | train(mse)=0.2009 | val_mse=0.1656 val_mae=0.3336\n",
      "Epoch 40/100 | train(mse)=0.1397 | val_mse=0.1922 val_mae=0.3604\n",
      "Epoch 60/100 | train(mse)=0.1178 | val_mse=0.2217 val_mae=0.3716\n",
      "Epoch 80/100 | train(mse)=0.0905 | val_mse=0.1712 val_mae=0.3268\n",
      "Epoch 100/100 | train(mse)=0.0675 | val_mse=0.3255 val_mae=0.4630\n",
      "Finished: loss=mse mode=stochastic | test_mse=0.6058 test_mae=0.5540 time=7.74s\n",
      "\n",
      "=== Running: loss=mse | mode=minibatch ===\n",
      "Epoch 1/100 | train(mse)=0.8670 | val_mse=0.4765 val_mae=0.5509\n",
      "Epoch 20/100 | train(mse)=0.3113 | val_mse=0.2002 val_mae=0.3495\n",
      "Epoch 40/100 | train(mse)=0.2746 | val_mse=0.1821 val_mae=0.3387\n",
      "Epoch 60/100 | train(mse)=0.2570 | val_mse=0.1746 val_mae=0.3344\n",
      "Epoch 80/100 | train(mse)=0.2453 | val_mse=0.1710 val_mae=0.3311\n",
      "Epoch 100/100 | train(mse)=0.2368 | val_mse=0.1699 val_mae=0.3284\n",
      "Finished: loss=mse mode=minibatch | test_mse=0.5220 test_mae=0.5392 time=0.42s\n",
      "\n",
      "=== Running: loss=mae | mode=batch ===\n",
      "Epoch 1/100 | train(mae)=0.7773 | val_mse=0.5995 val_mae=0.6278\n",
      "Epoch 20/100 | train(mae)=0.6892 | val_mse=0.5026 val_mae=0.5620\n",
      "Epoch 40/100 | train(mae)=0.6242 | val_mse=0.4339 val_mae=0.5019\n",
      "Epoch 60/100 | train(mae)=0.5715 | val_mse=0.3784 val_mae=0.4602\n",
      "Epoch 80/100 | train(mae)=0.5270 | val_mse=0.3336 val_mae=0.4282\n",
      "Epoch 100/100 | train(mae)=0.4959 | val_mse=0.2992 val_mae=0.4060\n",
      "Finished: loss=mae mode=batch | test_mse=0.9154 test_mae=0.6927 time=0.15s\n",
      "\n",
      "=== Running: loss=mae | mode=stochastic ===\n",
      "Epoch 1/100 | train(mae)=0.5067 | val_mse=0.2394 val_mae=0.3609\n",
      "Epoch 20/100 | train(mae)=0.3208 | val_mse=0.2388 val_mae=0.3600\n",
      "Epoch 40/100 | train(mae)=0.2909 | val_mse=0.2752 val_mae=0.3882\n",
      "Epoch 60/100 | train(mae)=0.2740 | val_mse=0.2215 val_mae=0.3633\n",
      "Epoch 80/100 | train(mae)=0.2591 | val_mse=0.2261 val_mae=0.3589\n",
      "Epoch 100/100 | train(mae)=0.2497 | val_mse=0.2867 val_mae=0.4078\n",
      "Finished: loss=mae mode=stochastic | test_mse=0.5973 test_mae=0.5545 time=9.09s\n",
      "\n",
      "=== Running: loss=mae | mode=minibatch ===\n",
      "Epoch 1/100 | train(mae)=0.7490 | val_mse=0.5343 val_mae=0.5850\n",
      "Epoch 20/100 | train(mae)=0.4154 | val_mse=0.2260 val_mae=0.3554\n",
      "Epoch 40/100 | train(mae)=0.3791 | val_mse=0.2188 val_mae=0.3473\n",
      "Epoch 60/100 | train(mae)=0.3636 | val_mse=0.2072 val_mae=0.3410\n",
      "Epoch 80/100 | train(mae)=0.3499 | val_mse=0.1966 val_mae=0.3344\n",
      "Epoch 100/100 | train(mae)=0.3411 | val_mse=0.1925 val_mae=0.3300\n",
      "Finished: loss=mae mode=minibatch | test_mse=0.5664 test_mae=0.5435 time=0.41s\n",
      "\n",
      "All experiments done. Results:\n",
      "  loss_used_for_training        mode  test_mse  test_mae  train_time_sec\n",
      "0                    mse       batch  0.694397  0.607101            0.31\n",
      "1                    mse  stochastic  0.605781  0.553979            7.74\n",
      "2                    mse   minibatch  0.522044  0.539233            0.42\n",
      "3                    mae       batch  0.915425  0.692670            0.15\n",
      "4                    mae  stochastic  0.597261  0.554473            9.09\n",
      "5                    mae   minibatch  0.566402  0.543547            0.41\n",
      "\n",
      "Saved results to results.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Main runner\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting experiments...\")\n",
    "\n",
    "    results = run_experiments(CSV_PATH,\n",
    "                              hidden_neurons=HIDDEN_NEURONS,\n",
    "                              lr=LEARNING_RATE,\n",
    "                              max_epochs=MAX_EPOCHS,\n",
    "                              minibatch_size=MINIBATCH_SIZE,\n",
    "                              random_seed=RANDOM_SEED)\n",
    "\n",
    "    # save results\n",
    "    results_csv = \"results.csv\"\n",
    "    results.to_csv(results_csv, index=False)\n",
    "    print(\"\\nAll experiments done. Results:\")\n",
    "    print(results)\n",
    "    print(f\"\\nSaved results to {results_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "scaler = MinMaxScaler()\n",
    "# Balik ke skala asli\n",
    "y_pred = scaler.inverse_transform(y_pre)\n",
    "y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(\"MAE (rupiah):\", mae)\n",
    "print(\"MSE (rupiah^2):\", mse)\n",
    "print(\"RMSE (rupiah):\", np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
